<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><title>西瓜书笔记：1-2章(绪论，统计基础) [ the Garden of Sinners ]</title><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0,maximum-scale=1.0, user-scalable=no"><meta name="robot" content="index,follow"><meta name="format-detection" content="telephone=no"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="renderer" content="webkit"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="stylesheet" href="/css/sprinter.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1464257_drr710yuepc.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/5.10.2/css/all.min.css"><link rel="stylesheet" href="/thirdparty/highlightjs/styles/atelier-dune-light.css"><link rel="stylesheet" href="/thirdparty/sharejs/dist/css/share.min.css"></head><body><div class="wrap"><header><div class="avatar"><div class="avatar-black"></div><img class="avatar-img" src="/images/avatar.png"></div><div class="mobile-dropdown"><div class="author"><h1 class="author-name">MeowAlien喵星人</h1><div class="author-keywords"><span>Machine Learning</span><span>ACG</span><span>Kyokushin</span></div></div><div class="motto"> <h3>——式。我一生都不会原谅你</h3></div><nav><ul class="menu"><li><a class="index-menu-link" href="/about">About</a></li><li><a class="index-menu-link" href="https://github.com/MeowAlienOwO/CV">Resume</a></li><li><a class="index-menu-link" href="/archives">Archives</a></li></ul></nav><div class="social"><a class="social-icon social-icon-color-github" href="https://github.com/MeowAlienOwO"><i class="iconfont icon-github"></i></a><a class="social-icon social-icon-color-weibo" href="https://www.weibo.com/u/3027659753/home?wvr=5"><i class="iconfont icon-weibo"></i></a><a class="social-icon social-icon-color-mail" href="mailto:meowalienowo@outlook.com"><i class="iconfont icon-mail"></i></a><a class="social-icon social-icon-color-bilibili" href="https://space.bilibili.com/1374912"><i class="iconfont icon-bilibili"></i></a></div></div></header><div class="content"><div class="card" id="post"><div class="post-cover"><img src="https://i.loli.net/2019/10/23/uiTGNX8Eyta6zlo.jpg"><div class="cover-author"><a href="https://www.pixiv.net/artworks/47069731">画师: 樹土 風</a></div></div><div class="post-title"><h1 id="title">西瓜书笔记：1-2章(绪论，统计基础)</h1><time id="date" datetime="2019-12-17T09:16:00.000Z">2019年12月17日</time></div><article class="md-article container"><p>开始认真刷西瓜书了，作为面试的准备。规划是重点公式+有价值的练习题推一遍或者编程实现，由于同时也要刷 leetcode 与找内推所以更新不定。本文会包括 1-2 章的内容以及习题。</p>
<p>一些碎碎念：之前跟朋友聊的时候说到在瓶颈期要保持产出——不论是知识还是产品，那么现在姑且就把知识整理一下吧，虽然做的有点晚，但是总比不做好。博客改成hexo以后好多以前的文章暂时没空搬过来，可能要留到以后整理了，因为好多图放在七牛但是七牛现在对未备案域名有限制所以全挂了，怎么处理得慢慢来了。</p>
<p>迁移到hexo的时候也有好多坑，可能另外有空说一下，包括但不限于 Mathjax 引入，代码高亮，分享……（想在leancloud注册账号，要人脸认证但是我手机不给认证……）等。而且实际上主题没写完，手机端的样式没仔细调，一些页面的样式没写，等等。但是毕竟是从头写起的一个主题，拖延了好久的想法终于实现80%，感觉还是不错的。<br><a id="more"></a></p>
<h1 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章 绪论"></a>第一章 绪论</h1><h2 id="一些基本概念的定义"><a href="#一些基本概念的定义" class="headerlink" title="一些基本概念的定义"></a>一些基本概念的定义</h2><ul>
<li>机器学习：使用计算的手段，利用经验改进自身性能。</li>
<li>模型：从数据中学的的结果。模型习得的是关于规律的一个假设 (hypothesis)，真实的规律被称为 ground truth</li>
<li>数据集： 数据的集合，每条记录是一个样本。也有认为数据集是一个对整个样本空间进行采样的样本。</li>
<li>特征向量：样本对应的属性的向量化，表示为特征空间的一个向量。</li>
<li>分类：预测值为离散值</li>
<li>回归：预测值为连续值</li>
<li>训练集，测试集: 训练集用于学习模型，测试集用于测试模型的性能</li>
<li>有监督学习：训练集上的样本给定标记信息</li>
<li>无监督学习：训练集上的样本无标记信息或者监督信息</li>
<li>泛化：学习的模型在未见过的样本上的适应能力</li>
<li>假设空间：所有可能的假设（模型）所组成的空间，学习的过程可以看做是在假设空间中搜索一个最适用的模型的过程</li>
<li>版本空间：与训练集一致的假设集合</li>
</ul>
<h2 id="归纳偏好"><a href="#归纳偏好" class="headerlink" title="归纳偏好"></a>归纳偏好</h2><p>由于训练集只是样本空间的某些采样的集合，仅仅依赖训练样本我们可以训练出若干个模型，但是没有办法判断哪种模型更好。为了选出更优的模型，我们会对某些类型有一些偏好（比如泛化能力等），这种偏好叫做假设偏好。</p>
<p>根据假设偏好，我们能够选出更优的模型；但是只有当假设偏好于问题匹配的时候，我们才能根据假设偏好选择出更适用于实际问题的模型。<br>根据“没有免费午餐”定理（证明见书），在真实目标函数是均匀分布的情况下，任何学习算法的期望性能都相同。换言之，讨论学习算法的性能与好坏必须基于实际问题，归纳偏好一定要与实际问题相符才能得出正确的结论。</p>
<p>机器学习的发展历史略。</p>
<h2 id="习题"><a href="#习题" class="headerlink" title="习题"></a>习题</h2><h3 id="西瓜数据集"><a href="#西瓜数据集" class="headerlink" title="西瓜数据集"></a>西瓜数据集</h3><p>先给出西瓜数据集1.1：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>编号</th>
<th>色泽</th>
<th>根蒂</th>
<th>敲声</th>
<th>好瓜</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>青绿</td>
<td>蜷缩</td>
<td>浊响</td>
<td>T</td>
</tr>
<tr>
<td>2</td>
<td>乌黑</td>
<td>蜷缩</td>
<td>浊响</td>
<td>T</td>
</tr>
<tr>
<td>3</td>
<td>青绿</td>
<td>硬挺</td>
<td>清脆</td>
<td>F</td>
</tr>
<tr>
<td>4</td>
<td>乌黑</td>
<td>稍卷</td>
<td>沉闷</td>
<td>F</td>
</tr>
</tbody>
</table>
</div>
<p>从表中我们得到</p>
<ul>
<li>特征空间：<br>  1.色泽：青绿、乌黑<br>  2.根蒂：蜷缩、硬挺、稍卷<br>  3.敲声：浊响、清脆、沉闷</li>
<li>标记空间：<ul>
<li>好瓜：T、F</li>
</ul>
</li>
</ul>
<h3 id="习题及解答"><a href="#习题及解答" class="headerlink" title="习题及解答"></a>习题及解答</h3><blockquote>
<p>1.1  表中若只包含1， 4两个样例，求版本空间</p>
</blockquote>
<p>假设空间的大小为每个属性的取值数 +1 （泛化在所有取值的操作符 *) 的连乘+1 再加上空集（即概念无效）</p>
<script type="math/tex; mode=display">
1 + \prod_{k=1}^K (\#k+1)</script><p>我们要做的是两步:</p>
<ol>
<li>删除不包含数据1（正例）的假设</li>
<li>在上一步的基础上删除包含数据1与数据4的假设</li>
</ol>
<p>结果如下：</p>
<ol>
<li><code>青绿，蜷缩，浊响</code>(均无泛化的情况下，有唯一正例)</li>
<li><code>青绿，蜷缩，\*</code>；<code>青绿，\*，浊响</code>；<code>\*，蜷缩，浊响</code>(一个泛化)</li>
<li><code>青绿，\*, \*</code>；<code>\*, 蜷缩, \*</code>；<code>\*, \*, 浊响</code>(两个泛化)</li>
</ol>
<p>排除空集（有正例）与全部泛化（有反例）</p>
<blockquote>
<p>1.2 用析合范式表示数据集1.1的假设空间，计算可能的假设数，析合范式包含 k 个合取式</p>
</blockquote>
<p>首先，基于数据集我们可以计算出合取式的假设空间 (k=1) 为 3 * 4 *4 + 1 = 49</p>
<p>以下讨论定义<script type="math/tex">\#</script> 为计数函数。</p>
<ol>
<li>单独处理空集，取消空集后的选择数为 \(N = C_{48}^k\) ，加上空集的组合为 \(2N+1\)(所有组合都可并一个空集，加上单独的空集自身)</li>
<li>对三个属性泛化的表达式 <code>A = (a=*, b=*, c=*)</code> 与其他所有的泛化式均有：<code>(A or B) = A</code>，即<script type="math/tex">C_{47}^{k-1}</script></li>
<li>对两个属性泛化的表达式形如 <code>A = (a=0, b=*, c=*)</code>，重复的冗余形如 <code>B = (a=0, b=1, c=*)</code>。我们可以删除一个属性，<code>A&#39; = (b=*, c=*)</code>求其所有可能的泛化组合：<script type="math/tex">C_{\#_b\times\#_c+1}^{k-1}</script>，b, c 为非a的属性。两个属性的泛化表达式一共有<script type="math/tex">\sum_i \#_i</script>种。</li>
<li>对一个属性泛化的表达式形如 <code>A = (a=0, b=1, c=*)</code>，重复的冗余形如 <code>B = (a=0, b=1, c=2)</code>。其泛化组合即为<script type="math/tex">C_{\#c}^{k-1}</script>，一共有<script type="math/tex">\sum_i \#_a \#_b</script>种，其中<code>a, b</code>为非泛化的属性。</li>
<li>补集的情况不知道是不是算冗余，如果是的话情况会比较复杂，会跟k有关。</li>
</ol>
<p><a href="https://blog.csdn.net/icefire_tyh/article/details/52065626" target="_blank" rel="noopener">这里</a> 有一个编程实现，应当是考虑了补集的。</p>
<blockquote>
<p>1.3 若数据包含噪声，设计一种归纳偏好</p>
</blockquote>
<p>简单地说，特征类似应当具有类似的输出，但是这个要具体问题具体分析（反例：特征工程做得不好，有很多无效的特征,e.g. 特征向量维度 100 但是实际有用的维度只有1，此时这个归纳偏好就不太好）。</p>
<blockquote>
<p>1.4 用其他性能度量证明没有免费午餐定理</p>
</blockquote>
<p>TODO</p>
<h1 id="第二章-模型评估与选择"><a href="#第二章-模型评估与选择" class="headerlink" title="第二章 模型评估与选择"></a>第二章 模型评估与选择</h1><h2 id="经验误差与过拟合"><a href="#经验误差与过拟合" class="headerlink" title="经验误差与过拟合"></a>经验误差与过拟合</h2><p>对于分类任务而言，若样本数为 m，分类错误数为 a， 则错误率定义为<script type="math/tex">E=a/m</script>，精度为<script type="math/tex">A = 1-E</script>。更一般的，我们将实际预测输出与样本真实输出的差异称作误差。在训练集上的误差为训练误差或者经验误差(training error)，在新样本上的误差为泛化误差(generalization error)。</p>
<p>过拟合指的是学习器在训练样本上学习的“太好”，以至于在非训练样本上表现的不好，即泛化误差大于训练误差。欠拟合指的是在训练样本上没有恰当地学习到模型。在真实的任务中，欠拟合比较少见而过拟合比较多见，所以我们通常集中于讨论如何避免过拟合。</p>
<h2 id="测试集及其划分"><a href="#测试集及其划分" class="headerlink" title="测试集及其划分"></a>测试集及其划分</h2><p>测试集通常用于判断样本的泛化能力。给定有 m 个数据的数据集 D，我们将其划分为测试集 T 与训练集 S。一般而言划分有如下方法： </p>
<ul>
<li>留出法：直接将数据集划分成两个互斥集合。我们在划分数据集的时候通常需要保证数据分布的一致性，避免划分的偏差影响结果。另外，测试集过小会导致测试结果不够稳定准确，测试集过大会导致学习的模型的性能不够好。一般而言训练集占比为 2/3 到 4/5。</li>
<li>交叉验证(cross validation) 将数据集先划分为 k 个互斥子集，对于每个子集尽量保持数据一致性；然后抽出一个作为测试集，剩余的合并成为训练集，从而进行 k 次训练。结果是这 k 次的均值。特例：留一法：子集的粒度划分到每一个样本。其好处是，评估的效果会跟真实效果比较接近；坏处是计算量偏大。</li>
<li>自助法(bootstrapping): 留出与交叉验证都会引入一些根据数据分布的不稳定因素，留一法能够最大程度上减小这种估计  偏差但是计算量太大。自助法以自助采样为基础，给定大小为 m 的数据集 D，每次随机挑选一个样本放入采样数据集 D’。执行 m 次后我们获得了一个包含 m 个样本的数据集 D’。 样本不被采集到的的概率为<code>1-(1/m)^m</code>，取 m 趋于无穷的极限得到大约有 1/e (36.5%)的样本不被采集到。于是我们可以将 D’ 用作训练集， <code>D - D&#39;</code> 用作测试集。自助法用于数据比较小的情况，而且自助法能够产生不同的数据集，对集成学习有好处；但是对初始数据集分布的改变也会引入偏差，因此在数据集足够的时候用的比较少。</li>
</ul>
<h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><h3 id="均方误差，精度与错误率"><a href="#均方误差，精度与错误率" class="headerlink" title="均方误差，精度与错误率"></a>均方误差，精度与错误率</h3><p>如上文所述，分类任务通常使用错误率与精度来衡量学习器的性能。对于回归任务而言， 常用的性能度量是均方误差(mean square error)：</p>
<script type="math/tex; mode=display">
E(f;D) = \frac{1}{m} \sum_{i=1}^m (f(\mathbf{x}_i)-y_i)^2</script><p>其积分形式可以用于描述更为一般的数据分布:</p>
<script type="math/tex; mode=display">
E(f;\mathcal{D}) = \int_{x\sim \mathcal{D}} (f(\mathbf{x}) - y)^2p(\mathbf{x})d\mathbf{x}</script><p>类似的，分类错误率定义为：</p>
<script type="math/tex; mode=display">
E(f;D) = \frac{1}{m} \sum_{i=1}^m \mathbb{I}(f(\mathbf{x}_i) \neq y_i)\\

E(f;\mathcal{D}) = \int_{x\sim \mathcal{D}} \mathbb{I}(f(\mathbf{x}) \neq y)p(\mathbf{x})d\mathbf{x}</script><p>精度定义为：</p>
<script type="math/tex; mode=display">
E(f;D) = \frac{1}{m} \sum_{i=1}^m \mathbb{I}(f(\mathbf{x}_i) = y_i)\\

E(f;\mathcal{D}) = \int_{x\sim \mathcal{D}} \mathbb{I}(f(\mathbf{x}) = y)p(\mathbf{x})d\mathbf{x}</script><h3 id="混淆矩阵与F1-score"><a href="#混淆矩阵与F1-score" class="headerlink" title="混淆矩阵与F1 score"></a>混淆矩阵与F1 score</h3><p>单单使用精度或者错误率不能满足所有任务需求。我们通常用查准率，查全率与 F-1 score 来更全面地描述学习器的性能。<br>对二分类任务，我们有真正例(TP)，假正例(FP)，真反例(TN)，假反例(FN)四种情况，如下即为相关的混淆矩阵：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">真实/预测</th>
<th style="text-align:center">正例</th>
<th style="text-align:center">反例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">正例</td>
<td style="text-align:center">TP</td>
<td style="text-align:center">FN</td>
</tr>
<tr>
<td style="text-align:center">反例</td>
<td style="text-align:center">FP</td>
<td style="text-align:center">TN</td>
</tr>
</tbody>
</table>
</div>
<p>我们定义查准率 P 与查全率 R:</p>
<script type="math/tex; mode=display">
P = \frac{TP}{TP+FP}\\
R = \frac{TP}{TP+FN}</script><p>查准率-查全率是有一定矛盾的，希望查准率高，就会尽可能地减少数量，这就会导致查全率变少；提高查全率则反之。为了更全面地比较，我们可以画出P-R曲线图。一般曲线能够完全包住另一个学习器的情况，就说明该算法较优。另一方面，F-1 score 是另一种结合上述两种度量的性能度量</p>
<script type="math/tex; mode=display">
F1 =\frac{2PR}{P + R}</script><p>对于多次训练/多个数据集的情况，我们通常对一次训练计算一次混淆矩阵，然后求全局的平均P, R 值，再计算全局的 F1 score。</p>
<h3 id="ROC-AUC"><a href="#ROC-AUC" class="headerlink" title="ROC, AUC"></a>ROC, AUC</h3><p>考虑这样一种分类器：其输出值是 0-1 之间的实数，我们设定一个分类阈值，比如 0.5，来决定输出的标签是正类还是反类。我们可以将样本按照输出值进行排序。如果不考虑阈值，这个实值的好坏决定了分类器的好坏：如果这个值分的更开，说明分类越好。我们可以直观的理解其下界：以均匀分布随机输出实值。在这个排序中，调整截断点的位置可以体现对 P 或者 R 的重视程度，而排序本身体现了期望泛化性能的好坏。</p>
<p>ROC 曲线就是一种应用了这种思想的曲线，纵轴是真正例率(TPR)，横轴是假正例率(FPR)。其计算如下：</p>
<script type="math/tex; mode=display">
TPR = \frac{TP}{TP+FN}\\
FPR = \frac{FP}{TN+FP}</script><p>类似的，我们可以与P-R曲线一样判断 ROC 曲线下学习器的优劣：能够全包的曲线一般更优。在没有办法全包的情况，我们一般计算曲线包围的面积 AUC。由于我们一般在离散的样本上进行学习测试，其曲线也是曲折的，我们用一个个小矩形来近似 AUC:</p>
<script type="math/tex; mode=display">
AUC = \frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1} - x_i)(y_i + y_{i+1})</script><h3 id="代价敏感错误率与代价曲线"><a href="#代价敏感错误率与代价曲线" class="headerlink" title="代价敏感错误率与代价曲线"></a>代价敏感错误率与代价曲线</h3><p>现实中不同类型的错误造成的后果不同：比如在医疗诊断中，将患者诊断为健康可能造成不可控的后果，但是将健康人诊断为患病的后果就相对比较小。为了权衡不同类型错误的损失，可以为错误赋予非均等代价。我们可以设定代价矩阵：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>真实类别/预测类别</th>
<th>第0类</th>
<th>第1类</th>
</tr>
</thead>
<tbody>
<tr>
<td>第0类</td>
<td>0</td>
<td>c01</td>
</tr>
<tr>
<td>第1类</td>
<td>c10</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p>我们可以计算代价敏感错误率，令<script type="math/tex">D^+</script>, <script type="math/tex">D^-</script> 分别为正，反例子集：</p>
<script type="math/tex; mode=display">
E(f;D; c) = \frac{1}{m} (\sum_{\mathbf{x}_i \in D^+}\mathbb{I}(f(\mathbf{x}_i \neq y_i))\times c_{01}\\
+ \sum_{\mathbf{x}_j \in D^-}\mathbb{I}(f(\mathbf{x}_j \neq y_i)) \times c_{10})</script><p>在非均等代价下， ROC 曲线不能直接反映期望总体代价，我们使用代价曲线来取代。其横轴为<script type="math/tex">[0,1]</script>的正例概率代价</p>
<script type="math/tex; mode=display">
P(+)cost = \frac{p\times c_{01}}{p\times c_{01} + (1-p)\times{c10}}</script><p>取<script type="math/tex">p</script>为正例概率。纵轴是取值为<script type="math/tex">[0,1]</script>的归一化代价：</p>
<script type="math/tex; mode=display">
c_{norm} = \frac{FNR\times p \times c_{01} + FPR\times(1-p) \times c_{10}}{p\times c_{01} + (1-p)\times c{10}}</script><p>在ROC曲线上，每一点的坐标是(TPR, FPR)。我们可以计算出假反例率 FNR=1-TPR，从而可以在代价敏感图中画出一条从(0, FNR) 到 (1, FPR) 的线段，所有线段的下界包起来的面积即为期望总体代价。</p>
<h2 id="比较检验"><a href="#比较检验" class="headerlink" title="比较检验"></a>比较检验</h2><p>我们通常用测试集上的某些性能度量来衡量学习器的性能，但是：</p>
<ul>
<li>泛化性能跟测试集上的性能未必相同</li>
<li>测试集的性能跟测试集自身的选择密切相关</li>
<li>算法本身的随机性导致测试集上的性能未必相同</li>
</ul>
<p>基于这些问题，我们使用统计假设检验(hypothesis test)帮助我们比较学习器的性能。假设检验能让我们推断出，如果测试集上观察到某个学习器A比学习器B优，那么 A 泛化性能是否比 B 好，以及该结论把握多大。根据<a href="https://www.zhihu.com/question/287895170" target="_blank" rel="noopener">知乎</a>的解释，西瓜书这里的公式2.27有误，正确的推理如下：</p>
<p>令泛化错误率为<script type="math/tex">\epsilon</script>, 测试错误率为<script type="math/tex">\hat \epsilon</script>。在测试集上，恰有<script type="math/tex">\hat\epsilon\times m</script>个样本被误分类。根据泛化错误恰好将测试集上错误分类的概率为：</p>
<script type="math/tex; mode=display">
P(\hat\epsilon;\epsilon) = 
                            \begin{pmatrix}m\\
                            \hat\epsilon \times m\\
                            \end{pmatrix}
                            \epsilon^{\hat\epsilon\times m}(1-\epsilon)^{m-\hat\epsilon\times m}</script><p>当测试错误率与泛化错误率相等时，<script type="math/tex">P</script>最大。考虑假设<script type="math/tex">\epsilon < \epsilon_0</script>（泛化错误率小于某个阈值）。<br>原假设<script type="math/tex">H_0: \epsilon \leq \epsilon_0</script>，备择假设<script type="math/tex">H_1: \epsilon>\epsilon_0</script>。</p>
<p>若原假设成立，那么采样测试错误率小于某个临界值<script type="math/tex">\hat\epsilon \leq \overline \epsilon</script>。从条件概率的角度理解：<script type="math/tex">P(\hat\epsilon \leq \overline \epsilon |H_0) >= 1-\alpha</script>。等价于<script type="math/tex">P(\hat\epsilon \gt \overline \epsilon | H_0) < \alpha</script>。 其中，<script type="math/tex">1-\alpha</script>为置信度，意思即为原假设成立的概率。</p>
<p>我们需要计算这个观测临界值<script type="math/tex">\overline\epsilon</script>。考虑西瓜书图2.6类似的概率分布，误分类样本为右侧的阴影表示。这个概率分布表示所有可能的误分类数发生的概率。想象在概率分布图上画一根竖线分割概率密度函数曲线为两个部分，右侧为小概率事件发生，需要拒绝原假设（拒绝域）；左侧为大概率事件发生，接受原假设（接受域）。这条线<script type="math/tex">0 < l < 1</script>是接受域的上限，拒绝域的下限。我们需要拒绝域的面积最大为<script type="math/tex">\alpha</script>，则我们需要寻找一个最小的<script type="math/tex">l</script>，使得右边阴影面积最大为<script type="math/tex">\alpha</script></p>
<script type="math/tex; mode=display">
\overline\epsilon = \min \epsilon~s.t. \sum_{i=\epsilon\times m+1}^{m} \begin{pmatrix}m\\
                                         i \\
                                         \end{pmatrix}\epsilon_0^i(i-\epsilon_0)^{m-i} < \alpha</script><p>这个<script type="math/tex">\overline\epsilon</script>就是我们的接受域上界。</p>
<h3 id="t检验"><a href="#t检验" class="headerlink" title="t检验"></a>t检验</h3><p>我们对使用交叉验证或者多次重复留出法可以得到多个测试错误率，此时可以使用 t 检验。首先计算平均错误率与方差：</p>
<script type="math/tex; mode=display">
\mu = \frac{1}{k} \sum_{i=1}^k \hat\epsilon_i\\
\sigma^2 = \frac{1}{k-1} \sum_{i=1}^k(\hat\epsilon_i - \mu)^2</script><p>我们将其看做是对泛化错误率的独立采样:</p>
<script type="math/tex; mode=display">
\tau_t = \frac{\sqrt{k}(\mu - \epsilon_0)}{\sigma}</script><p>这个统计量服从于自由度为 <script type="math/tex">t-1</script> 的 t 分布。类似的，左右两边的阴影大小分别应该为 <script type="math/tex">\frac{\alpha}{2}</script>。如果平均错误率与 <script type="math/tex">\epsilon_0</script>之差在分布的中间，则可以接受原假设。</p>
<h3 id="交叉验证t检验"><a href="#交叉验证t检验" class="headerlink" title="交叉验证t检验"></a>交叉验证t检验</h3><p>我们对 A, B 两个学习器分别求 k-fold 交叉验证，得到两组错误率；同时，我们又可以得到两组错误率之差。因此，我们可以对这两组错误率之差做 t 检验。计算差值的平均值与方差，令变量<script type="math/tex">\tau_t = |\frac{\sqrt{k}\mu}{\sigma}|</script>。我们将原假设设为两个学习器的性能没有区别，用类似的方法来处理这个变量，以判断是否接受原假设。</p>
<h3 id="McNemar-检验"><a href="#McNemar-检验" class="headerlink" title="McNemar 检验"></a>McNemar 检验</h3><p>对于二分类问题，我们有两个学习器A，B，不仅可以计算其错误率，也可以计算其分类结果的差别：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>B/A</th>
<th>正确</th>
<th>错误</th>
</tr>
</thead>
<tbody>
<tr>
<td>正确</td>
<td>e00</td>
<td>e01</td>
</tr>
<tr>
<td>错误</td>
<td>e10</td>
<td>e11</td>
</tr>
</tbody>
</table>
</div>
<p>如果我们假设两学习器性能相同，则e01 = e10，那么 |e01 - e10| 应服从正态分布，均值为1，方差为 e01+e10。令变量</p>
<script type="math/tex; mode=display">
\tau_{\chi^2} = \frac{(|e_{01} - e_{10}|-1)^2}{e_{01} + e_{10}}</script><p>服从于自由度为1的卡方分布。</p>
<h3 id="Friedman-检验-Nemenyi检验"><a href="#Friedman-检验-Nemenyi检验" class="headerlink" title="Friedman 检验 Nemenyi检验"></a>Friedman 检验 Nemenyi检验</h3><p>见书，感觉用的不是很多，要用的时候查一下吧。<br>F检验大致的思想：对各个算法在不同数据集上的性能进行排序，如果他们性能相同，那么他们的平均序值应当相同。<br>如果其性能不相同，那么我们可以用 Nemenyi 后续检验来进一步区分各个算法：给出一个临界值，如果两个算法平均序值之差超过临界值，则拒绝两个算法性能相同这一假设。</p>
<h2 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h2><p>偏差-方差分解是一个比较重要的工具。给定数据集 D 学习器 f, 对测试样本 x，令 yd 为数据集中的标记，y 为真实标记。<br>对于回归任务，学习算法的期望预测：</p>
<script type="math/tex; mode=display">
\hat f(\mathbf{x}) = \mathbb{E}_D[f(\mathbf{x}; D)]</script><p>样本相同，不同的训练集产生的方差为：</p>
<script type="math/tex; mode=display">
var(\mathbf{x}) = \mathbb{E}_D[(f(\mathbf{x};D)-\hat f(\mathbf{x}))^2]</script><p>噪声为</p>
<script type="math/tex; mode=display">
\epsilon^2 = \mathbb{E}_D[(y_D - y)^2]</script><p>期望输出与真实标记之间的差别称为偏差(bias)：</p>
<script type="math/tex; mode=display">
bias^2(\mathbf{x}) = (\hat f(\mathbf{x}) - y)^2</script><p>推导过程见书，从期望泛化误差开始推导。我们证明泛化误差可分解为偏差，方差与噪声之和。<br>偏差度量学习器输出与真实的偏离程度，即算法本身的拟合能力；方差度量同样大小的训练集变动所导致的学习性能变化，即数据扰动的影响；噪声定义了期望泛化误差的下界。这意味着泛化性能由学习器本身的学习能力，数据的充分性与学习任务本身的难度共同决定。</p>
<p>一般而言方差与偏差是有冲突的，训练不足，学习器拟合能力不强，偏差主导对泛化性能的影响；训练充分，学习能力足够强，训练数据的扰动被学习器习得，从而方差的影响程度逐步加深；当训练过拟合，数据的微小扰动都会导致方差的巨大变化。</p>
<h2 id="习题-1"><a href="#习题-1" class="headerlink" title="习题"></a>习题</h2><blockquote>
<p>1000个样本, 500正例500反例。划分为包含70%的训练集与30%的测试集用于留出法评估，估算划分方式</p>
</blockquote>
<p>没有额外信息，我们保证正例跟反例在训练集跟测试集里的比重相等。</p>
<script type="math/tex; mode=display">
C_{500}^{350} \times C_{500}^{350}</script><blockquote>
<p>100个样本，正，反例各一半，假定学习算法的新模型是将新样本预测为训练样本较多的类。给出用10折交叉验证与留一法分别对错误率进行评估所得的结果</p>
</blockquote>
<p>10折：理想情况下正，反例在整个数据集与每个fold的分布都是均匀的，错误率期望是 50%<br>留一法：每次取一个样本，剩下的样本会有49个同类，50个相反，错误率是100%</p>
<blockquote>
<p>若学习器 A 的 F1 值比 B 高，求 A 的 BEP 值是否也更高</p>
</blockquote>
<p>不一定，感觉这两个没有明确的关系，见<a href="https://zhuanlan.zhihu.com/p/42435889" target="_blank" rel="noopener">知乎</a></p>
<blockquote>
<p>真正例率，假正例率，查准率，查全率之间的关系</p>
</blockquote>
<script type="math/tex; mode=display">
TPR = \frac{TP}{TP + FN}\\
FPR = \frac{FP}{FP+TN} \\
P = \frac{TP}{TP+FP} \\
R = \frac{TP}{TP+FN} \\</script><p>显然，TPR = R</p>
<blockquote>
<p>证明式 2.22</p>
</blockquote>
<p>数学玩法参考<a href="https://zhuanlan.zhihu.com/p/42435889" target="_blank" rel="noopener">这里</a></p>
<p>我们要证明的是：</p>
<script type="math/tex; mode=display">
\mathcal{l}_{rank} = \frac{1}{m^+m^-} \sum_{\mathbf{x}^+\in D^+}\sum{\mathbf{x}^-\in D^-} (\mathbb{I}(f(\mathbf{x}^+)< f(\mathbf{x}^-))+ \frac{1}{2}\mathbb{I}(f(\mathbf{x}^+) = f(\mathbf{x}^-))) \\ 
AUC = 1 - \mathcal{l}_{rank}</script><p><a href="https://blog.csdn.net/icefire_tyh/article/details/52065867" target="_blank" rel="noopener">这里</a>有比较详细的说明。</p>
<!-- 借用一下 ROC 曲线的图片： -->
<p><img src="/images/roc-ml.jpg" alt="ROC_curve"></p>
<p>如图，横轴纵轴分别被分割为<script type="math/tex">1/m^-</script>，<script type="math/tex">1/m^+</script>的小条，划分出每个小块面积为<script type="math/tex">1/m^-1/m^+</script>都代表一对样本对(a, b)。当<script type="math/tex">f(a) > f(b)</script>且a为正例，b为反例的时候，这个方块在ROC曲线下方；当两者相等，则用一个占一半面积的三角形替代。于是损失函数等同于在上方的方块数+一半的边界三角形数乘以单位面积，即为ROC曲线上方的面积。</p>
<blockquote>
<p>ROC曲线与错误率的关系</p>
</blockquote>
<p>ROC曲线上每一点都对应一个错误率。<br>不考虑代价，我们有：</p>
<script type="math/tex; mode=display">
E = \frac{FP+FN}{TP+FP+TN+FN}\\</script><p>TPR, FPR见上。我们有</p>
<script type="math/tex; mode=display">
FP = FPR \times (FP+TN)\\
FN = (1-TPR)\times(TP+FN)</script><p>另外注意到FP+TN, TP+FN 分别为正例，反例的数量，所以我们可以得到</p>
<script type="math/tex; mode=display">
E = (FPR \times m^- + (1-TPR)\times m^+)/ (m^+ + m^-)</script><blockquote>
<p>试证明任意一条ROC曲线都有一条代价曲线与之对应，反之亦然。</p>
</blockquote>
<p>代价曲线是代价敏感图的下界，由于每一条代价线都是(0, FNR)到(1, FPR)的线段，而TPR=1-FNR，可以得出每一条代价线都能转换成(TPR, FNR)的形式，即ROC线上一点。由于代价曲线是这些线段族下确界组成的多边形，每个代价曲线都可以写成若干在ROC曲线上的点。反之，则可根据ROC曲线上的点做线段，取下界得到代价曲线。</p>
<blockquote>
<p>min-max规范与z-score规范化的优缺点</p>
</blockquote>
<p>min-max适用于规范化最大，最小值已知的情况，缺点是对极端数据敏感，出现极端数据需要取舍<br>z-score适用于未知的情况，或者有极端数据。另外数据归零化。缺点是计算量大，出现新数据要重新计算。</p>
<blockquote>
<p>卡方分布检验过程，Friedman检验</p>
</blockquote>
<p>略，不懂统计……</p>
</article><div class="post-footer"><div class="tags"><span><i class="fas fa-tag"></i></span><a href="/tags/ml/"><span class="tag">ml</span></a><a href="/tags/西瓜书/"><span class="tag">西瓜书</span></a><a href="/tags/statistic/"><span class="tag">statistic</span></a></div><div class="share"><div class="social-share" data-image="https://i.loli.net/2019/10/23/uiTGNX8Eyta6zlo.jpg" data-sites="weibo,wechat,qq,twitter,facebook"></div><script src="/thirdparty/sharejs/dist/js/share.min.js"></script></div></div></div><footer><div><span>Site construction by</span><span> MeowAlien喵星人 </span><span>using </span><span></span><a href="http://hexo.io">hexo</a><span>.</span><br></div></footer></div></div><script src="//cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script><script src="/js/sprinter.js"></script><script>configMath()</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  "HTML-CSS": { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } }
});
</script><script id="MathJax-script" src="//cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script src="/thirdparty/highlightjs/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></body></html>