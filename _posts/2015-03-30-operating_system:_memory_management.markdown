---
layout: post
title: "操作系统笔记二：内存管理"
date: "2015-03-30 19:10:06 +0800"
modified: 
description: 
categories: [Computer Science, Operating System]
tags: [Memory Management, Computer Science, Operating System, notes]
image:
  feature: 27167056.jpg
  credit: TYPE-MOON10YEARS!! | STAR影法師 [pixiv]
  creditlink: http://www.pixiv.net/member_illust.php?mode=medium&illust_id=27167056
comments:
---

操作系统笔记之二，内存管理。每一次上操作系统跟MAL都是智商上的一种煎熬啊……跟上一篇同样，这也是一些翻译ppt的内容，充作笔记。


# 基础知识
## 硬件存储器层级与操作系统

现代的算机通常有如下几种存储层级，由速度快慢排列如下：

1. 寄存器，1/2/3级缓存
2. 主内存
3. 硬盘

更高级的存储器更快，但是代价更加昂贵以及更加容易被改变，低级的则相反。
内存可以被认为是一个线性的字节/单词的数组，而操作系统负责提供内存的抽
象。

操作系统负责：

1. 根据进程的请求分配/收回内存
2. 追踪内存的使用情况
3. “透明地”(Transparently)在内存与硬盘之间移动信息
4. 在进程之间分配内存，模拟"无限大"的内存空间
5. 多任务的情况下，负责控制权限分配

## 内存管理模型

内存管理模型有两种：连续模型与非连续模型。

连续模型将所有的内存看作单个内存块，而非连续模型将内存分为若干内存块，
或者称之为段(segments)。这些段可以在物理内存中的任何位置，而不需要一定与彼此相邻。

至于内存的分区方面，对于单任务系统而言，只需要一个分区即可。而对于多任务系统而言，分区有多种方案。多任务系统可以是动态分区的，也可以是固定分区的。对于固定分区而言，有相等分区与不等分区两种。

### 单任务系统

单任务系统每次只允许一个用户进程在内存中被执行。内存的一部分被操作系统使用，而另外一部分被用户系统所使用("MS-DOS"方式)。被操作系统所使用的部分一般而言是固定大小的，通常可以直接使用物理内存。

<table border="1">
<tr>
<th>...</th>
<th>用户进程</th>
<th>...</th>
<th>操作系统内核</th>
</tr>
</table>


这种方式没有保护用户进程的必要，因为同一时间只有一个程序在运行。由于一个进程通常使用了所有的内存空间，同一进程通常被分配在同样的内存地址。当然，程序员可以用覆盖的方法来使用更多的空间，但是这种方法看起来更容易造成麻烦。

对于单任务系统而言，它的缺点是显而易见的：
1. 由于用户进程可以直接使用物理内存，它有可能会对操作系统的内存进行读写。
2. 如果我们将操作系统自身看作一个进程的话，实际上有两个进程同时运行(ppt原话翻译，我的理解是这可能是因为虽然是两个进程，但是由于单任务的特性，一次只能运行一个进程，这也意味着操作系统进程在用户进程被激活时是处于suspend状态，结合前面的直接读取权限，很可能用户进程对操作系统内存的读写是没有保护的。另一个问题可能也是进程排程的问题，操作系统进程无法跟用户进程协同。)
3. 对硬件资源的利用率低(比如说IO)
4. 无法适应需要多任务的场景

尽管如此，单任务系统依然在一些基础的嵌入式系统与家电中广泛运用。


### 多任务系统

从另一个角度而言，我们可以通过上下文切换来在单任务系统上模拟多任务：当需要切换进程的时候，将进程信息保存至硬盘，然后将新的进程信息读入并执行。但是这必然带来昂贵的开销。于是，真正的多任务系统就必不可少了。

我们首先做一个假设：进程会使用$p%$的时间来等待IO事务。那么，当内存中有$n$个进程的时候，所有的$n$个进程等待IO的概率为$p^n$，而CPU的利用率为$1 - p^n$。显而易见的，当同时运行的进程越多时，CPU的利用率越高，而当面向IO的进程变多时，CPU的利用率会相对有所降低。

但是，这个假设是建立在所有进程都是相互独立的基础上的，而在现实中，这是不可能的。不过我们仍旧可以用其来进行粗略的估算。

假设一个计算机有1M的内存，操作系统使用了200k，剩下的空间分配给4个200k的进程。那么CPU的利用率就将在60%以下。如果我们增加1M内存，将这些内存分配给5个200k的进程，那么我们的CPU利用率就有了87%。如果我们再增加1M的内存，我们就会得到大于96%的CPU利用率。由此看出，多线程可以很有效地提高资源利用率。

#### 固定分区（同等大小）

固定分区方法将所有用于用户进程的内存分成固定大小的若干个段，这些段拥有固定大小以及固定的位置。

优点：

* 任何进程都可以使用任何足够大的分区
* 开销较小，同时实现简单
* 操作系统只需要追踪被使用的区块与空闲的区块即可

缺点：

* 内存利用率相对较低，内部碎片化程度(internal fragmentation)在分区过大的情况下会很高，分区可能会过大
* 如果程序太大，需要重写内存（折腾程序员）
* 分区过小，追踪、分配的开销会变得很大

同时，固定分区还需要考虑如何将区块分配给任务，如何决定交换等。于是我们需要一些其他的策略来解决这些问题。

#### 固定分区改（不同等大小）

不同等大小分区策略将分区分成大小不同的几个固定区块，这样做的好处是可以增加内存使用率，以及可以更加灵活地分配资源。内部碎片化的程度也因此可以得到控制。相对的，对于不同等大小分区而言，我们需要考虑的是如何将合适的分区分配给相对应的进程。

一种策略是，对于每个分区，我们设置一个私有队列，每次分配进程时，将其安排在空间足够大，且最小的分区:`p.size < m.size && m.isMin`。这种策略，由于每次都能保证进程分配的分区足够且最小，内部碎片度会很有效地减少。但是相对的，内存使用率就会下降（总是将进程分配给最小的段），以及会导致饥饿的发生。

另一种策略则将队列设为全局的，对于每一个进程，分配给当前可用的、装的下的最小队列:`p.size < m.size && m.isAvailable && m.isMin`。
这种策略没有那么容易饥饿(可以将小程序分给大分区)，然而相对的，内部碎片化程度也会相对提高。

另一方面，我们需要注意的是，对内存需求的计算依赖于在程序开始时的估算，而程序的内存需求可能会随着运行而改变。同时，我们也无从预先得知程序运行时内存的分配情况。而进程更可能会被交换(swap)出去，然后被重新载入。那么，我们需要动态的去改变内存分配。

# 地址管理


## 基础知识

+ 相对分配(relocation)：操作系统无法在程序运行之前预先知道这个程序的分区与地址。这就意味着操作系统不能简单地静态地分配绝对地址，而相对的，地址必须根据运行时的情况进行相对分配。

+ 保护：当有复数的程序在内存中运行时，必须进行保护。

+ 逻辑地址(logical address)是进程所知道的内存形式。其独立于当前的物理内存，比如同程序的开始地址相对。

+ 物理地址(physical address)表示在主内存中的实际地址。逻辑地址空间必须以某种方式映射到物理地址空间上。

## 管理方法

- 编译时静态相对分配内存：一个进程每次都会被放在相同的地址
- 在载入时动态相对分配内存：逻辑地址是相对的，每次载入的时候通过计算偏移量来分配内存块。这会使载入变慢。
- 运行时动态分配内存

在CPU中，有两个特殊的寄存器用来存储基准地址(base address)与极限(limit)。基准寄存器用于储存分区的开始地址(start address)，极限寄存器用来存储分区的极限

运行时，基准寄存器的地址加上逻辑地址就可以得出物理地址，得出的结果会同极限寄存器中储存的值进行比较来判断是否有效。这种方式需要硬件支持。

固定分区会导致内部碎片(internal fragmentation)：与进程需求完全一致的分区可能不存在，那么空间就有可能没有被完全使用。于此相反，动态分区可以动态地改变内存的开始地址与极限地址。同时，一个进程通常会被分配一块与其内存需求完全相符的连续地址，这就很有效的减少了内存的碎片化程度。

## 交换(swapping)

交换可以将进程的一部分信息保存在硬盘里，然后在主内存跟硬盘之间交换信息。

我们需要使用交换的理由如下：

+ 我们可能有多余分区数的进程数量（假设我们使用固定分区方法）
+ 总内存的需求大于空余内存需求
+ 一些进程只是偶尔运行
+ 进程的内存需求可能会改变


外部碎片：
进程的交换也可能会导致内存的碎片化。将一个进程交换出去时，内存中会留下来一个“洞”，当另外的程序使用这个"洞"时，可能并没有使用整个空间，这样一来就会导致一些小小的，没有使用过的内存碎片。同时，一个新进程可能对于这个空间而言过大，那么就有可能导致这个空间自身成为一个碎片。另一方面，对于内存压缩来说，寻找这些碎片的代价也是非常高昂的，同时也需要动态的相对内存分配。

现在，内存管理的问题是：

- 如何快速地将可用的内存分配给进程
- 如何追踪内存的使用->链表/表

## 动态分区

我们需要一个更加复杂的内存分配数据结构来处理可变的使用与空闲的分区数量。

### 链表
链表是一个可以实现如此的数据结构。示意图如下：

<table border="1">
<tr><th>入口指针</th></tr>

<tr>
<th>是否空闲？</th>
<th>开始地址</th>
<th>大小</th>
<th>next指针</th>
</tr>
<tr>...</tr>
<tr>
<th>是否空闲？</th>
<th>开始地址</th>
<th>大小</th>
<th>next指针</th>
</tr>
<tr>...</tr>
<tr>
<th>是否空闲？</th>
<th>开始地址</th>
<th>大小</th>
<th>next指针(结束)</th>
</tr>
</table>



#### 第一匹配算法(first fit algorithm)

在初始化的时候，整个内存被认为是一整块，标记为空闲(free)。

当请求内存时，遍历整个链表，直到找到一个足够大的空闲空间。如果这个空间恰好需求相等时，将这块空间标记为使用(used)。如果这块空间比需求的空间大，将接下来的空间切分成另一块链表的节点，标记为空闲。当一块内存被释放时，该内存被设定为空闲。

#### 匹配算法改-第二匹配算法(second fit algorithm)

第一匹配算法的近代化改修型。

第一匹配算法在第一次请求内存时开始进行扫描，而第二匹配算法保存一个当前搜索位置的指针。第二次搜索时，从上一次扫描的结尾开始。这种算法可以保证所有的内存块都被扫描。但是第二匹配算法在实验中表现出来的效率比第一匹配差。

#### 匹配算法改二-最佳匹配算法(best fit algorithm)

第一匹配只匹配第一个<strong>足够大</strong>的空间，假设在之后的链表中存在一个恰好符合的空间，那么就会导致内存碎片的出现。

最佳匹配算法总是选择一个大小最适合的区块进行分配。然而，由于搜索的存在，必然会导致整个算法的速度降低。同时，令人惊讶的是，这种算法也会导致更高的内存浪费——每个“最合适”的区块万一不是恰好，就会被分割出一块最小的空间。

#### 配算法改三-最差匹配算法(worst fit algorithm)

为了防止最佳匹配算法所导致的大量碎片内存，最差匹配算法每次都会选择一块最大的内存，这样子切分下来的内存就通常会有更高的可用性。

然而在实际应用中似乎并没有什么卵用。

#### 快速匹配与其他算法
(存疑，待续)

### 点阵(bitmap)

作为链表的一种补充，点阵也是一种有效的数据结构。

内存被分割成特定的大小，例如4k。内存如果是空闲的，那么就会在点阵表中
标记为1, 反之为0。

当然，我们需要在内存块大小与点阵表的大小之间做一个恰当的取舍。过小的内存分块会使得搜索点阵变得困难，而过大的内存块分割会导致内部碎片的发生。

#### 联合(coalescing)

当两个相邻的链表中的内存块

